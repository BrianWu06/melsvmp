---
output: github_document
bibliography: references.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# melsvmp

<!-- badges: start -->
<!-- badges: end -->

The package "melsvmp" is an implementation of a Variational Message Passing algorithm for fitting Mixed-Effect Location-Scale model, which is defined as: 
```math
\begin{aligned}
y_{ij} &= x_{ij}^\top \beta + \nu_i + \varepsilon_{ij} \\
\nu_i &\sim \mathcal{N}(0, \exp{(U_i^\top \alpha)}) \\
\varepsilon_{ij} &\sim \mathcal{N}(0, \exp{(W_{ij}^\top \tau + \omega_i)}) \\
\omega_i &\sim \mathcal{N}(0, \sigma_\omega^2)
\end{aligned}
```

For more information, please refer to @hedeker2013mixregls. Note that our model formulation is a restricted to only allow for non time-varying covariates for $\alpha$ and without the effect of $\nu_i$ on $\omega_i$.

Some reviews of Variational Inference (VI) and Variational Message Passing (VMP) algorithms can be found in @blei2017variational and @ormerod2010explaining.
Briefly speaking, VI introduces surrogate distributions $q(\theta)$ to approximate the posterior distribution $p(\theta \mid x)$ by minimizing the KL-divergence of these two distributions. While the KL-divergence is often intractable, we will instead optimize the Evidence Lower Bound (ELBO): 
```math
\mathrm{ELBO} = \mathbf{E}_q[\log p(\theta, x)] - \mathbf{E}_q[\log q(\theta)]
```

A common approach to make this approximation computationally efficient is to use the mean-field assumption, which assumes $q(\Theta) = q(\theta_1) \cdots q(\theta_m)$ for the set of all latent variables $\Theta = \{ \theta_1, \dots, \theta_m \}$. 
Under this assumption, we can get clean update equations for conjugate variables (@blei2017variational) and non-conjugate ones using Laplace approximation (@wand2014fully). 

## Installation

You can install the development version of melsvmp like so:

```{r}
# install.packages("devtools")
# devtools::install_github("BrianWu06/melsvmp")
```


## Example

This is a basic example showing how to use the function mels_vmp to fit a MELS model. We use a simple longitudinal dataset "riesby" to illustrate the usage, you can import and view the description of this dataset by 
```{r}
library(melsvmp)

data(riesby)
?riesby
```

The following code shows how to fit a MELS model with our vmp algorithm on the riesby dataset. The standard errors and confidence intervals are estimated by the sandwich estimators proposed by @westling2019beyond.
```{r example}
riesby_vmp <- mels_vmp(y = "hamd", 
                       beta_formula = ~ week + endog + endweek, 
                       alpha_formula = ~ endog, 
                       tau_formula = ~ week + endog, 
                       id = "id",
                       data = riesby)
summary(riesby_vmp)
```

For performing percentile bootstrap, you can use the following code, we support both parallel and sequential computing. This can give a more robust confidence interval.
```{r}
# riesby_vmp_boot <- bootstrap_mels_vmp(riesby_vmp, B = 1000, cores = 10)
riesby_vmp_boot <- bootstrap_mels_vmp(riesby_vmp, B = 1000, parallel = FALSE)
summary(riesby_vmp_boot)
```

## References